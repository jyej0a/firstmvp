/**
 * @file lib/scraper/sequential-scraper.ts
 * @description ìˆœì°¨ ì²˜ë¦¬ ìŠ¤í¬ë˜í•‘ ë¡œì§
 *
 * ì´ íŒŒì¼ì€ 1ë¶„ë‹¹ 1ê°œì”© ìˆœì°¨ì ìœ¼ë¡œ ìƒí’ˆì„ ìˆ˜ì§‘í•˜ê³ ,
 * DB ì €ì¥ ë° Shopify ë“±ë¡ê¹Œì§€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * 1. Job ìƒì„± ë° ê´€ë¦¬ (scraping_jobs í…Œì´ë¸”)
 * 2. ìˆœì°¨ ì²˜ë¦¬ ë£¨í”„ (1ê°œ ìˆ˜ì§‘ â†’ í•„í„°ë§ â†’ ì €ì¥ â†’ ë“±ë¡)
 * 3. ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
 * 4. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
 *
 * @see {@link /docs/PRD.md} - KPI: 1ë¶„ë‹¹ 1ê°œ ìˆ˜ì§‘, í•˜ë£¨ ìµœëŒ€ 1000ê°œ
 * @see {@link /supabase/migrations/20251215153310_create_scraping_jobs_table.sql} - Job í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ
 */

import { getServiceRoleClient } from "@/lib/supabase/service-role";
import { filterByBannedKeywords } from "@/lib/utils/filter-banned-keywords";
import { saveProductsToDatabase } from "@/lib/utils/save-products";
import { createProduct } from "@/lib/shopify/client";
import { scrapeSingleProduct } from "./amazon-scraper";
import type { ScrapedProductRaw, Product } from "@/types";

/**
 * Job ìƒíƒœ íƒ€ì…
 */
export type JobStatus = "pending" | "running" | "completed" | "failed" | "cancelled";

/**
 * Job Item ìƒíƒœ íƒ€ì…
 */
export type JobItemStatus = "pending" | "scraping" | "saved" | "registered" | "failed";

/**
 * Job ìƒì„± ì¸í„°í˜ì´ìŠ¤
 */
export interface CreateJobParams {
  userId: string;
  searchInput: string;
  totalTarget?: number; // ê¸°ë³¸ê°’: 1000
}

/**
 * Job ì •ë³´ ì¸í„°í˜ì´ìŠ¤
 */
export interface JobInfo {
  id: string;
  userId: string;
  searchInput: string;
  status: JobStatus;
  totalTarget: number;
  currentCount: number;
  successCount: number;
  failedCount: number;
  startedAt: string | null;
  completedAt: string | null;
  errorMessage: string | null;
  createdAt: string;
  updatedAt: string;
}

/**
 * Job ì§„í–‰ ìƒí™© ì¸í„°í˜ì´ìŠ¤
 */
export interface JobProgress {
  jobId: string;
  status: JobStatus;
  currentCount: number;
  totalTarget: number;
  successCount: number;
  failedCount: number;
  estimatedTimeRemaining: number; // ì´ˆ ë‹¨ìœ„
  progressPercentage: number; // 0-100
}

/**
 * ìˆœì°¨ ìŠ¤í¬ë˜í•‘ ì‹œì‘
 *
 * Jobì„ ìƒì„±í•˜ê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆœì°¨ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
 * ì¦‰ì‹œ Job IDë¥¼ ë°˜í™˜í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ê°€ ì§„í–‰ ìƒí™©ì„ ì¡°íšŒí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
 *
 * @param params - Job ìƒì„± íŒŒë¼ë¯¸í„°
 * @returns ìƒì„±ëœ Job ID
 */
export async function startSequentialScraping(
  params: CreateJobParams
): Promise<string> {
  console.group("ğŸš€ [Sequential Scraper] Job ì‹œì‘");
  const { userId, searchInput, totalTarget = 1000 } = params;

  console.log(`ğŸ‘¤ ì‚¬ìš©ì ID: ${userId}`);
  console.log(`ğŸ” ê²€ìƒ‰ ì…ë ¥: ${searchInput}`);
  console.log(`ğŸ¯ ëª©í‘œ ê°œìˆ˜: ${totalTarget}ê°œ`);

  try {
    const supabase = getServiceRoleClient();

    // 1. Job ìƒì„±
    const { data: job, error: jobError } = await supabase
      .from("scraping_jobs")
      .insert({
        user_id: userId,
        search_input: searchInput,
        status: "pending",
        total_target: totalTarget,
        current_count: 0,
        success_count: 0,
        failed_count: 0,
      })
      .select()
      .single();

    if (jobError || !job) {
      console.error("âŒ Job ìƒì„± ì‹¤íŒ¨:", jobError);
      throw new Error(`Job ìƒì„± ì‹¤íŒ¨: ${jobError?.message || "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"}`);
    }

    console.log(`âœ… Job ìƒì„± ì™„ë£Œ: ${job.id}`);

    // 2. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ (ë¹„ë™ê¸° ì‹¤í–‰, await í•˜ì§€ ì•ŠìŒ)
    processSequentialScraping(job.id, userId, searchInput, totalTarget).catch(
      (error) => {
        console.error("âŒ ìˆœì°¨ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜:", error);
        // Job ìƒíƒœë¥¼ 'failed'ë¡œ ì—…ë°ì´íŠ¸
        updateJobStatus(job.id, "failed", error.message).catch((updateError) => {
          console.error("âŒ Job ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", updateError);
        });
      }
    );

    console.log("âœ… ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ë¨");
    console.groupEnd();

    return job.id;
  } catch (error) {
    console.error("âŒ Job ì‹œì‘ ì‹¤íŒ¨:", error);
    console.groupEnd();
    throw error;
  }
}

/**
 * ìˆœì°¨ ì²˜ë¦¬ ë©”ì¸ ë¡œì§
 *
 * 1ê°œì”© ìƒí’ˆì„ ìˆ˜ì§‘í•˜ê³ , í•„í„°ë§, ì €ì¥, ë“±ë¡ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 *
 * @param jobId - Job ID
 * @param userId - ì‚¬ìš©ì ID
 * @param searchInput - ê²€ìƒ‰ ì…ë ¥ê°’
 * @param totalTarget - ëª©í‘œ ê°œìˆ˜
 */
async function processSequentialScraping(
  jobId: string,
  userId: string,
  searchInput: string,
  totalTarget: number
): Promise<void> {
  console.group(`ğŸ”„ [Sequential Scraper] Job ${jobId} ì²˜ë¦¬ ì‹œì‘`);

  try {
    const supabase = getServiceRoleClient();

    // 1. Job ìƒíƒœë¥¼ 'running'ìœ¼ë¡œ ë³€ê²½
    await updateJobStatus(jobId, "running");
    const startedAt = new Date().toISOString();
    await supabase
      .from("scraping_jobs")
      .update({ started_at: startedAt })
      .eq("id", jobId);

    console.log(`âœ… Job ìƒíƒœ: running`);
    console.log(`ğŸ¯ ëª©í‘œ: ${totalTarget}ê°œ ìˆ˜ì§‘`);

    // 2. URL ì²˜ë¦¬ (í‚¤ì›Œë“œ â†’ Amazon URL ë³€í™˜)
    const { processSearchInput } = await import("@/lib/utils/url-processor");
    const processed = processSearchInput(searchInput);
    const searchUrl = processed.url;

    console.log(`ğŸ”— ê²€ìƒ‰ URL: ${searchUrl}`);

    // 3. ìˆœì°¨ ì²˜ë¦¬ ë£¨í”„
    let currentCount = 0;
    let successCount = 0;
    let failedCount = 0;
    let lastRequestTime = 0; // Rate Limitingìš©

    while (currentCount < totalTarget) {
      try {
        // ì·¨ì†Œ ìƒíƒœ ì²´í¬ (ë£¨í”„ ì‹œì‘ ì‹œë§ˆë‹¤ í™•ì¸)
        const currentJob = await supabase
          .from("scraping_jobs")
          .select("status")
          .eq("id", jobId)
          .single();

        if (currentJob.data?.status === "cancelled") {
          console.log(`ğŸ›‘ Job ì·¨ì†Œ ê°ì§€, ë£¨í”„ ì¢…ë£Œ`);
          console.groupEnd();
          return; // ë£¨í”„ ì¢…ë£Œ
        }

        // Rate Limiting ì²´í¬ (1ë¶„ë‹¹ 1ê°œ)
        const now = Date.now();
        const timeSinceLastRequest = now - lastRequestTime;
        const minIntervalMs = 60 * 1000; // 1ë¶„

        if (timeSinceLastRequest < minIntervalMs && lastRequestTime > 0) {
          const waitTime = minIntervalMs - timeSinceLastRequest;
          console.log(`â³ Rate Limit ëŒ€ê¸°: ${Math.ceil(waitTime / 1000)}ì´ˆ`);
          
          // ëŒ€ê¸° ì¤‘ì—ë„ ì·¨ì†Œ ìƒíƒœ ì²´í¬ (1ì´ˆë§ˆë‹¤)
          const checkInterval = 1000; // 1ì´ˆ
          const totalChecks = Math.ceil(waitTime / checkInterval);
          
          for (let i = 0; i < totalChecks; i++) {
            await new Promise((resolve) => setTimeout(resolve, checkInterval));
            
            // ì·¨ì†Œ ìƒíƒœ ì²´í¬
            const checkJob = await supabase
              .from("scraping_jobs")
              .select("status")
              .eq("id", jobId)
              .single();

            if (checkJob.data?.status === "cancelled") {
              console.log(`ğŸ›‘ Job ì·¨ì†Œ ê°ì§€, ëŒ€ê¸° ì¤‘ë‹¨`);
              console.groupEnd();
              return; // ë£¨í”„ ì¢…ë£Œ
            }
          }
        }

        console.log(`\nğŸ“¦ [${currentCount + 1}/${totalTarget}] ìƒí’ˆ ìˆ˜ì§‘ ì‹œì‘`);

        // 3-1. 1ê°œ ìƒí’ˆ ìˆ˜ì§‘
        let scrapedProduct: ScrapedProductRaw | null = null;
        let jobItemId: string | null = null;

        try {
          // Job Item ìƒì„± (pending ìƒíƒœ)
          const { data: jobItem, error: itemError } = await supabase
            .from("scraping_job_items")
            .insert({
              job_id: jobId,
              asin: "", // ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
              status: "pending",
            })
            .select()
            .single();

          if (itemError || !jobItem) {
            console.error("âŒ Job Item ìƒì„± ì‹¤íŒ¨:", itemError);
            throw new Error(`Job Item ìƒì„± ì‹¤íŒ¨: ${itemError?.message}`);
          }

          jobItemId = jobItem.id;

          // Job Item ìƒíƒœë¥¼ 'scraping'ìœ¼ë¡œ ë³€ê²½
          await supabase
            .from("scraping_job_items")
            .update({ status: "scraping" })
            .eq("id", jobItemId);

          // 1ê°œ ìƒí’ˆ ìˆ˜ì§‘ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
          let retryCount = 0;
          const maxRetries = 2; // ìµœëŒ€ 2íšŒ ì¬ì‹œë„

          while (retryCount <= maxRetries) {
            try {
              scrapedProduct = await scrapeSingleProduct(searchUrl, currentCount);

              if (!scrapedProduct) {
                throw new Error("ìƒí’ˆ ìˆ˜ì§‘ ì‹¤íŒ¨: ê²°ê³¼ê°€ nullì…ë‹ˆë‹¤");
              }

              break; // ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ
            } catch (retryError) {
              retryCount++;

              if (retryCount > maxRetries) {
                // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
                throw retryError;
              }

              // ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸° (1ì´ˆ, 2ì´ˆ)
              const delaySeconds = Math.pow(2, retryCount - 1);
              console.log(`â³ ì¬ì‹œë„ ${retryCount}/${maxRetries} - ${delaySeconds}ì´ˆ ëŒ€ê¸° ì¤‘...`);
              await new Promise((resolve) => setTimeout(resolve, delaySeconds * 1000));
            }
          }

          if (!scrapedProduct) {
            throw new Error("ìƒí’ˆ ìˆ˜ì§‘ ì‹¤íŒ¨: ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨");
          }

          // Job Itemì— ASIN ì—…ë°ì´íŠ¸
          await supabase
            .from("scraping_job_items")
            .update({ asin: scrapedProduct.asin })
            .eq("id", jobItemId);

          console.log(`âœ… ìˆ˜ì§‘ ì™„ë£Œ: ${scrapedProduct.title.substring(0, 50)}...`);
        } catch (scrapeError) {
          console.error("âŒ ìƒí’ˆ ìˆ˜ì§‘ ì‹¤íŒ¨:", scrapeError);
          failedCount++;
          currentCount++;

          // Job Item ìƒíƒœë¥¼ 'failed'ë¡œ ë³€ê²½
          if (jobItemId) {
            await supabase
              .from("scraping_job_items")
              .update({
                status: "failed",
                error_message:
                  scrapeError instanceof Error
                    ? scrapeError.message
                    : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜",
              })
              .eq("id", jobItemId);
          }

          // Job ìƒíƒœ ì—…ë°ì´íŠ¸
          await updateJobProgress(jobId, currentCount, successCount, failedCount);

          // ë‹¤ìŒ ìƒí’ˆìœ¼ë¡œ ê³„ì† ì§„í–‰
          lastRequestTime = Date.now();
          continue;
        }

        // 3-2. ê¸ˆì§€ì–´ í•„í„°ë§
        const filterResult = await filterByBannedKeywords([scrapedProduct]);

        if (filterResult.stats.filteredOut > 0) {
          console.log(`ğŸš« ê¸ˆì§€ì–´ í•„í„°ë§ìœ¼ë¡œ ì œì™¸ë¨`);
          failedCount++;
          currentCount++;

          // Job Item ìƒíƒœë¥¼ 'failed'ë¡œ ë³€ê²½
          if (jobItemId) {
            await supabase
              .from("scraping_job_items")
              .update({
                status: "failed",
                error_message: "ê¸ˆì§€ì–´ í¬í•¨ìœ¼ë¡œ í•„í„°ë§ë¨",
              })
              .eq("id", jobItemId);
          }

          await updateJobProgress(jobId, currentCount, successCount, failedCount);
          lastRequestTime = Date.now();
          continue;
        }

        const filteredProduct = filterResult.filteredProducts[0];

        // 3-3. DB ì €ì¥ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        let savedProductId: string | null = null;
        try {
          let saveRetryCount = 0;
          const maxSaveRetries = 1; // DB ì €ì¥ì€ 1íšŒ ì¬ì‹œë„

          while (saveRetryCount <= maxSaveRetries) {
            try {
              const saveResult = await saveProductsToDatabase([filteredProduct], userId);

              if (saveResult.saved === 0 || saveResult.failed > 0) {
                throw new Error(
                  `DB ì €ì¥ ì‹¤íŒ¨: ${saveResult.errors[0]?.error || "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"}`
                );
              }

              break; // ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ
            } catch (saveRetryError) {
              saveRetryCount++;

              if (saveRetryCount > maxSaveRetries) {
                throw saveRetryError;
              }

              // 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
              console.log(`â³ DB ì €ì¥ ì¬ì‹œë„ ${saveRetryCount}/${maxSaveRetries}...`);
              await new Promise((resolve) => setTimeout(resolve, 1000));
            }
          }

          // ì €ì¥ëœ ìƒí’ˆ ID ì¡°íšŒ
          const { data: savedProduct } = await supabase
            .from("products")
            .select("id")
            .eq("asin", filteredProduct.asin)
            .eq("user_id", userId)
            .single();

          savedProductId = savedProduct?.id || null;

          // Job Itemì— product_id ì—°ê²°
          if (jobItemId && savedProductId) {
            await supabase
              .from("scraping_job_items")
              .update({
                product_id: savedProductId,
                status: "saved",
              })
              .eq("id", jobItemId);
          }

          console.log(`âœ… DB ì €ì¥ ì™„ë£Œ`);
        } catch (saveError) {
          console.error("âŒ DB ì €ì¥ ì‹¤íŒ¨:", saveError);
          failedCount++;
          currentCount++;

          if (jobItemId) {
            await supabase
              .from("scraping_job_items")
              .update({
                status: "failed",
                error_message:
                  saveError instanceof Error
                    ? saveError.message
                    : "DB ì €ì¥ ì‹¤íŒ¨",
              })
              .eq("id", jobItemId);
          }

          await updateJobProgress(jobId, currentCount, successCount, failedCount);
          lastRequestTime = Date.now();
          continue;
        }

        // 3-4. Shopify ë“±ë¡ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        try {
          if (!savedProductId) {
            throw new Error("ì €ì¥ëœ ìƒí’ˆ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
          }

          // ì €ì¥ëœ ìƒí’ˆ ì •ë³´ ì¡°íšŒ
          const { data: productRow, error: productError } = await supabase
            .from("products")
            .select("*")
            .eq("id", savedProductId)
            .single();

          if (productError || !productRow) {
            throw new Error(`ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: ${productError?.message}`);
          }

          // DB ë°ì´í„°ë¥¼ Product íƒ€ì…ìœ¼ë¡œ ë³€í™˜ (snake_case â†’ camelCase)
          const product: Product = {
            id: productRow.id,
            userId: productRow.user_id,
            asin: productRow.asin,
            sourceUrl: productRow.source_url,
            title: productRow.title,
            description: productRow.description,
            images: productRow.images,
            variants: productRow.variants,
            sourcingType: productRow.sourcing_type as "US" | "CN",
            amazonPrice: Number(productRow.amazon_price),
            costPrice: productRow.cost_price ? Number(productRow.cost_price) : null,
            shippingCost: productRow.shipping_cost ? Number(productRow.shipping_cost) : null,
            extraCost: productRow.extra_cost ? Number(productRow.extra_cost) : null,
            marginRate: Number(productRow.margin_rate),
            sellingPrice: Number(productRow.selling_price),
            status: productRow.status as "draft" | "uploaded" | "error",
            errorMessage: productRow.error_message,
            createdAt: productRow.created_at,
            updatedAt: productRow.updated_at,
          };

          // Shopify ë“±ë¡ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
          let shopifyRetryCount = 0;
          const maxShopifyRetries = 1; // Shopify ë“±ë¡ì€ 1íšŒ ì¬ì‹œë„

          while (shopifyRetryCount <= maxShopifyRetries) {
            try {
              const shopifyResult = await createProduct(product);

              if (!shopifyResult.success) {
                throw new Error(shopifyResult.error || "Shopify ë“±ë¡ ì‹¤íŒ¨");
              }

              break; // ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ
            } catch (shopifyRetryError) {
              shopifyRetryCount++;

              if (shopifyRetryCount > maxShopifyRetries) {
                throw shopifyRetryError;
              }

              // 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
              console.log(`â³ Shopify ë“±ë¡ ì¬ì‹œë„ ${shopifyRetryCount}/${maxShopifyRetries}...`);
              await new Promise((resolve) => setTimeout(resolve, 2000));
            }
          }

          // Job Item ìƒíƒœë¥¼ 'registered'ë¡œ ë³€ê²½
          if (jobItemId) {
            await supabase
              .from("scraping_job_items")
              .update({ status: "registered" })
              .eq("id", jobItemId);
          }

          // products í…Œì´ë¸”ì˜ statusë¥¼ 'uploaded'ë¡œ ì—…ë°ì´íŠ¸
          await supabase
            .from("products")
            .update({ status: "uploaded" })
            .eq("id", savedProductId);

          console.log(`âœ… Shopify ë“±ë¡ ì™„ë£Œ`);
          successCount++;
        } catch (shopifyError) {
          console.error("âŒ Shopify ë“±ë¡ ì‹¤íŒ¨:", shopifyError);
          // Shopify ë“±ë¡ ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ìƒí’ˆ ê³„ì† ì§„í–‰
          // Job Itemì€ 'saved' ìƒíƒœ ìœ ì§€ (ë‚˜ì¤‘ì— ìˆ˜ë™ ë“±ë¡ ê°€ëŠ¥)
        }

        // 3-5. ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        currentCount++;
        await updateJobProgress(jobId, currentCount, successCount, failedCount);

        console.log(
          `ğŸ“Š ì§„í–‰ ìƒí™©: ${currentCount}/${totalTarget} (ì„±ê³µ: ${successCount}, ì‹¤íŒ¨: ${failedCount})`
        );

        // 3-6. ë‹¤ìŒ ìˆ˜ì§‘ ì „ 1ë¶„ ëŒ€ê¸° (Rate Limiting)
        lastRequestTime = Date.now();
        if (currentCount < totalTarget) {
          console.log(`â³ ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ 1ë¶„ ëŒ€ê¸° ì¤‘...`);
          await new Promise((resolve) => setTimeout(resolve, 60 * 1000));
        }
      } catch (loopError) {
        console.error("âŒ ë£¨í”„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", loopError);
        // ê°œë³„ ìƒí’ˆ ì²˜ë¦¬ ì‹¤íŒ¨ëŠ” ê³„ì† ì§„í–‰
        currentCount++;
        failedCount++;
        await updateJobProgress(jobId, currentCount, successCount, failedCount);
        lastRequestTime = Date.now();
      }
    }

    // 4. ì™„ë£Œ ì²˜ë¦¬
    const completedAt = new Date().toISOString();
    await supabase
      .from("scraping_jobs")
      .update({
        status: "completed",
        completed_at: completedAt,
      })
      .eq("id", jobId);

    console.log(`\nğŸ‰ Job ì™„ë£Œ!`);
    console.log(`   ì´ ìˆ˜ì§‘: ${currentCount}ê°œ`);
    console.log(`   ì„±ê³µ: ${successCount}ê°œ`);
    console.log(`   ì‹¤íŒ¨: ${failedCount}ê°œ`);
    console.groupEnd();
  } catch (error) {
    console.error("âŒ ìˆœì°¨ ì²˜ë¦¬ ì‹¤íŒ¨:", error);
    await updateJobStatus(
      jobId,
      "failed",
      error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
    );
    console.groupEnd();
    throw error;
  }
}

/**
 * Job ìƒíƒœ ì—…ë°ì´íŠ¸
 *
 * @param jobId - Job ID
 * @param status - ìƒˆë¡œìš´ ìƒíƒœ
 * @param errorMessage - ì—ëŸ¬ ë©”ì‹œì§€ (ì„ íƒì‚¬í•­)
 */
async function updateJobStatus(
  jobId: string,
  status: JobStatus,
  errorMessage?: string
): Promise<void> {
  const supabase = getServiceRoleClient();

  const updateData: any = {
    status,
    updated_at: new Date().toISOString(),
  };

  if (errorMessage) {
    updateData.error_message = errorMessage;
  }

  const { error } = await supabase
    .from("scraping_jobs")
    .update(updateData)
    .eq("id", jobId);

  if (error) {
    console.error("âŒ Job ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", error);
    throw new Error(`Job ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: ${error.message}`);
  }
}

/**
 * Job ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
 *
 * @param jobId - Job ID
 * @param currentCount - í˜„ì¬ ìˆ˜ì§‘ëœ ê°œìˆ˜
 * @param successCount - ì„±ê³µí•œ ê°œìˆ˜
 * @param failedCount - ì‹¤íŒ¨í•œ ê°œìˆ˜
 */
async function updateJobProgress(
  jobId: string,
  currentCount: number,
  successCount: number,
  failedCount: number
): Promise<void> {
  const supabase = getServiceRoleClient();

  const { error } = await supabase
    .from("scraping_jobs")
    .update({
      current_count: currentCount,
      success_count: successCount,
      failed_count: failedCount,
      updated_at: new Date().toISOString(),
    })
    .eq("id", jobId);

  if (error) {
    console.error("âŒ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", error);
    // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
  }
}

/**
 * Job ì§„í–‰ ìƒí™© ì¡°íšŒ
 *
 * @param jobId - Job ID
 * @returns Job ì§„í–‰ ìƒí™© ì •ë³´
 */
export async function getJobProgress(jobId: string): Promise<JobProgress | null> {
  const supabase = getServiceRoleClient();

  const { data: job, error } = await supabase
    .from("scraping_jobs")
    .select("*")
    .eq("id", jobId)
    .single();

  if (error || !job) {
    console.error("âŒ Job ì¡°íšŒ ì‹¤íŒ¨:", error);
    return null;
  }

  // ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)
  let estimatedTimeRemaining = 0;
  if (job.status === "running" && job.current_count < job.total_target) {
    const remaining = job.total_target - job.current_count;
    estimatedTimeRemaining = remaining * 60; // 1ë¶„ë‹¹ 1ê°œ
  }

  // ì§„í–‰ë¥  ê³„ì‚° (0-100)
  const progressPercentage =
    job.total_target > 0
      ? Math.round((job.current_count / job.total_target) * 100)
      : 0;

  return {
    jobId: job.id,
    status: job.status as JobStatus,
    currentCount: job.current_count,
    totalTarget: job.total_target,
    successCount: job.success_count,
    failedCount: job.failed_count,
    estimatedTimeRemaining,
    progressPercentage,
  };
}

/**
 * Job ì •ë³´ ì¡°íšŒ
 *
 * @param jobId - Job ID
 * @returns Job ì •ë³´
 */
export async function getJobInfo(jobId: string): Promise<JobInfo | null> {
  const supabase = getServiceRoleClient();

  const { data: job, error } = await supabase
    .from("scraping_jobs")
    .select("*")
    .eq("id", jobId)
    .single();

  if (error || !job) {
    console.error("âŒ Job ì¡°íšŒ ì‹¤íŒ¨:", error);
    return null;
  }

  return {
    id: job.id,
    userId: job.user_id,
    searchInput: job.search_input,
    status: job.status as JobStatus,
    totalTarget: job.total_target,
    currentCount: job.current_count,
    successCount: job.success_count,
    failedCount: job.failed_count,
    startedAt: job.started_at,
    completedAt: job.completed_at,
    errorMessage: job.error_message,
    createdAt: job.created_at,
    updatedAt: job.updated_at,
  };
}

/**
 * Job ì·¨ì†Œ
 *
 * @param jobId - Job ID
 * @returns ì·¨ì†Œ ì„±ê³µ ì—¬ë¶€
 */
export async function cancelJob(jobId: string): Promise<boolean> {
  console.group(`ğŸ›‘ [Sequential Scraper] Job ${jobId} ì·¨ì†Œ ìš”ì²­`);

  try {
    const supabase = getServiceRoleClient();

    // Job ìƒíƒœ í™•ì¸
    const jobInfo = await getJobInfo(jobId);
    if (!jobInfo) {
      console.error("âŒ Jobì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
      console.groupEnd();
      return false;
    }

    // ì´ë¯¸ ì™„ë£Œë˜ì—ˆê±°ë‚˜ ì·¨ì†Œëœ Jobì€ ì·¨ì†Œ ë¶ˆê°€
    if (jobInfo.status === "completed" || jobInfo.status === "cancelled") {
      console.warn(`âš ï¸  Jobì´ ì´ë¯¸ ${jobInfo.status} ìƒíƒœì…ë‹ˆë‹¤`);
      console.groupEnd();
      return false;
    }

    // Job ìƒíƒœë¥¼ 'cancelled'ë¡œ ë³€ê²½
    const cancelledAt = new Date().toISOString();
    const { error } = await supabase
      .from("scraping_jobs")
      .update({
        status: "cancelled",
        completed_at: cancelledAt,
        error_message: "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨",
        updated_at: cancelledAt,
      })
      .eq("id", jobId);

    if (error) {
      console.error("âŒ Job ì·¨ì†Œ ì‹¤íŒ¨:", error);
      console.groupEnd();
      return false;
    }

    console.log(`âœ… Job ì·¨ì†Œ ì™„ë£Œ`);
    console.log(`   ì·¨ì†Œ ì‹œì : ${cancelledAt}`);
    console.log(`   ìˆ˜ì§‘ëœ ìƒí’ˆ: ${jobInfo.currentCount}ê°œ`);
    console.groupEnd();

    return true;
  } catch (error) {
    console.error("âŒ Job ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜:", error);
    console.groupEnd();
    return false;
  }
}
